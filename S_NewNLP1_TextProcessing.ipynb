{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joXaY4CtrmmM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7273a29a-e01d-4bca-a69b-8f88658963a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n"
          ]
        }
      ],
      "source": [
        "# Inside nltk library you will get stop word, stemming, lemmatization. So install it\n",
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install clean-text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJXNg249IFMI",
        "outputId": "114e334c-5854-4a80-e1d4-363b936be9a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting clean-text\n",
            "  Downloading clean_text-0.6.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting emoji<2.0.0,>=1.0.0 (from clean-text)\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ftfy<7.0,>=6.0 (from clean-text)\n",
            "  Downloading ftfy-6.2.3-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy<7.0,>=6.0->clean-text) (0.2.13)\n",
            "Downloading clean_text-0.6.0-py3-none-any.whl (11 kB)\n",
            "Downloading ftfy-6.2.3-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.0/43.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171031 sha256=95dcd673fad40f981a378d4535a0747ae5aff053c491add988714e2e96864d38\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/8a/8c/315c9e5d7773f74b33d5ed33f075b49c6eaeb7cedbb86e2cf8\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji, ftfy, clean-text\n",
            "Successfully installed clean-text-0.6.0 emoji-1.7.0 ftfy-6.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk # Natural Language Tool Kit\n",
        "from nltk.tokenize import sent_tokenize,word_tokenize\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "# PortStemmer - for stemming\n",
        "# WordNetLematizer - for lemmatization\n",
        "import re # for regular expression - to clean data i.e. to remove special characters, emojis\n",
        "from cleantext import clean"
      ],
      "metadata": {
        "id": "QP8TYQ7lsNSG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "05059f09-246d-42cc-efbc-40a7dfc817be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# text data :para=\"\"\"paste whole paragraph here\"\"\"\n",
        "para = \"\"\"— Tensor and Tensorflow: A powerful combo 💪\n",
        "The Google Brain team developed an advanced AI framework named Tensorflow years back. After that, Google designed its own processing unit named Tensor Processing Unit or TPU to perform more efficiently with the Tensorflow. The invention of TPU was a revolution in AI that has significantly expedited the training of huge machine learning models with millions (or, billions) of parameters. Nevertheless, that technology could not be used in low-power devices such as smartphones in Edge AI. The entrance of Google into the AI chip manufacturing club for low-power devices can be the next revolution in this industry. Many companies such as FogHorn and BlinkAI are working in Edge AI using currently existing AI chips in the market. However, the efficacy that Google can create by the combination of TensorFlow and Tensor will be game-changing. Welcome to the club, Google!\n",
        "\n",
        "— Tensor is an AI chip designed by AI! 😲\n",
        "Isn’t that cool? The story is started from an article published in Nature titles “A graph placement methodology for fast chip design”. To design a processing chip, there is a crucial step referred to as “floor planning” where the engineering team must place a large number of components such that a series of physical requirements including power consumption and performance get satisfied. I don’t go further into its details as I am also not an expert in hardware engineering. However, when you have a large series of choices to make with a series of constraints AI can kick in. You may remember how the AlphaGo project defeated a professional human Go player. This is exactly the same. Tensor is the real outcome of this project that is a new milestone in the AI industry. Kudos, Google!\n",
        "\n",
        "— Tensor helps us build ethical AI. 💡\n",
        "This is a double-edged sword statement. Ethical AI has various aspects from data privacy to AI for all. Tensor helps many users have the opportunity to try the latest AI advancement while they have no concern about their privacy. Why? Because the AI engine is running on the chip, and no data is sent to the cloud for further computation. On the other hand, the more tightly Google binds AI software and hardware, the harder it will be for other companies to compete. I don’t want to see days that other companies can not even compete on performing AI inference, i.e., compete on using AI. We almost lost the game of model training to giant tech companies. It would be a nightmare if we lose the game on AI inference to them as well. That is why I believe “Tensor helps us build ethical AI” is a double-edged sword.\"\"\""
      ],
      "metadata": {
        "id": "2ya3pgBusvqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "para"
      ],
      "metadata": {
        "id": "ui49_rzGun_g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "e1deed2f-d2a8-4baf-8e92-6c2282fae500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'— Tensor and Tensorflow: A powerful combo 💪\\nThe Google Brain team developed an advanced AI framework named Tensorflow years back. After that, Google designed its own processing unit named Tensor Processing Unit or TPU to perform more efficiently with the Tensorflow. The invention of TPU was a revolution in AI that has significantly expedited the training of huge machine learning models with millions (or, billions) of parameters. Nevertheless, that technology could not be used in low-power devices such as smartphones in Edge AI. The entrance of Google into the AI chip manufacturing club for low-power devices can be the next revolution in this industry. Many companies such as FogHorn and BlinkAI are working in Edge AI using currently existing AI chips in the market. However, the efficacy that Google can create by the combination of TensorFlow and Tensor will be game-changing. Welcome to the club, Google!\\n\\n— Tensor is an AI chip designed by AI! 😲\\nIsn’t that cool? The story is started from an article published in Nature titles “A graph placement methodology for fast chip design”. To design a processing chip, there is a crucial step referred to as “floor planning” where the engineering team must place a large number of components such that a series of physical requirements including power consumption and performance get satisfied. I don’t go further into its details as I am also not an expert in hardware engineering. However, when you have a large series of choices to make with a series of constraints AI can kick in. You may remember how the AlphaGo project defeated a professional human Go player. This is exactly the same. Tensor is the real outcome of this project that is a new milestone in the AI industry. Kudos, Google!\\n\\n— Tensor helps us build ethical AI. 💡\\nThis is a double-edged sword statement. Ethical AI has various aspects from data privacy to AI for all. Tensor helps many users have the opportunity to try the latest AI advancement while they have no concern about their privacy. Why? Because the AI engine is running on the chip, and no data is sent to the cloud for further computation. On the other hand, the more tightly Google binds AI software and hardware, the harder it will be for other companies to compete. I don’t want to see days that other companies can not even compete on performing AI inference, i.e., compete on using AI. We almost lost the game of model training to giant tech companies. It would be a nightmare if we lose the game on AI inference to them as well. That is why I believe “Tensor helps us build ethical AI” is a double-edged sword.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(para) # returns no. of characters in sentence or paragraph"
      ],
      "metadata": {
        "id": "4jmva8a2xE0S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89160cf4-322e-4784-965b-8ddcf0be1934"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2602"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "para[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Jw9cCEFQJkdY",
        "outputId": "00368ce2-55ad-4842-e750-51c6682213c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'T'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove only Emojis\n",
        "clean(para,no_emoji=True) # converts text to lower case and removes emojis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "Q9qYDXCHJxAk",
        "outputId": "e72a9d28-b2ab-4a43-fc09-e5c2e49be213"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tensor and tensorflow: a powerful combo\\nthe google brain team developed an advanced ai framework named tensorflow years back. after that, google designed its own processing unit named tensor processing unit or tpu to perform more efficiently with the tensorflow. the invention of tpu was a revolution in ai that has significantly expedited the training of huge machine learning models with millions (or, billions) of parameters. nevertheless, that technology could not be used in low-power devices such as smartphones in edge ai. the entrance of google into the ai chip manufacturing club for low-power devices can be the next revolution in this industry. many companies such as foghorn and blinkai are working in edge ai using currently existing ai chips in the market. however, the efficacy that google can create by the combination of tensorflow and tensor will be game-changing. welcome to the club, google!\\ntensor is an ai chip designed by ai!\\nisn\\'t that cool? the story is started from an article published in nature titles \"a graph placement methodology for fast chip design\". to design a processing chip, there is a crucial step referred to as \"floor planning\" where the engineering team must place a large number of components such that a series of physical requirements including power consumption and performance get satisfied. i don\\'t go further into its details as i am also not an expert in hardware engineering. however, when you have a large series of choices to make with a series of constraints ai can kick in. you may remember how the alphago project defeated a professional human go player. this is exactly the same. tensor is the real outcome of this project that is a new milestone in the ai industry. kudos, google!\\ntensor helps us build ethical ai.\\nthis is a double-edged sword statement. ethical ai has various aspects from data privacy to ai for all. tensor helps many users have the opportunity to try the latest ai advancement while they have no concern about their privacy. why? because the ai engine is running on the chip, and no data is sent to the cloud for further computation. on the other hand, the more tightly google binds ai software and hardware, the harder it will be for other companies to compete. i don\\'t want to see days that other companies can not even compete on performing ai inference, i.e., compete on using ai. we almost lost the game of model training to giant tech companies. it would be a nightmare if we lose the game on ai inference to them as well. that is why i believe \"tensor helps us build ethical ai\" is a double-edged sword.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "para"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "D8TN2oMTJ9jK",
        "outputId": "671f1532-53bb-4a7d-aa76-64c12fc79cba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'— Tensor and Tensorflow: A powerful combo 💪\\nThe Google Brain team developed an advanced AI framework named Tensorflow years back. After that, Google designed its own processing unit named Tensor Processing Unit or TPU to perform more efficiently with the Tensorflow. The invention of TPU was a revolution in AI that has significantly expedited the training of huge machine learning models with millions (or, billions) of parameters. Nevertheless, that technology could not be used in low-power devices such as smartphones in Edge AI. The entrance of Google into the AI chip manufacturing club for low-power devices can be the next revolution in this industry. Many companies such as FogHorn and BlinkAI are working in Edge AI using currently existing AI chips in the market. However, the efficacy that Google can create by the combination of TensorFlow and Tensor will be game-changing. Welcome to the club, Google!\\n\\n— Tensor is an AI chip designed by AI! 😲\\nIsn’t that cool? The story is started from an article published in Nature titles “A graph placement methodology for fast chip design”. To design a processing chip, there is a crucial step referred to as “floor planning” where the engineering team must place a large number of components such that a series of physical requirements including power consumption and performance get satisfied. I don’t go further into its details as I am also not an expert in hardware engineering. However, when you have a large series of choices to make with a series of constraints AI can kick in. You may remember how the AlphaGo project defeated a professional human Go player. This is exactly the same. Tensor is the real outcome of this project that is a new milestone in the AI industry. Kudos, Google!\\n\\n— Tensor helps us build ethical AI. 💡\\nThis is a double-edged sword statement. Ethical AI has various aspects from data privacy to AI for all. Tensor helps many users have the opportunity to try the latest AI advancement while they have no concern about their privacy. Why? Because the AI engine is running on the chip, and no data is sent to the cloud for further computation. On the other hand, the more tightly Google binds AI software and hardware, the harder it will be for other companies to compete. I don’t want to see days that other companies can not even compete on performing AI inference, i.e., compete on using AI. We almost lost the game of model training to giant tech companies. It would be a nightmare if we lose the game on AI inference to them as well. That is why I believe “Tensor helps us build ethical AI” is a double-edged sword.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt') #For tokenization this package is required. If installed successfully we will get output as Trud"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hb_LOD55KCqa",
        "outputId": "8de1a4a9-e267-49d9-f6dc-599466185454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "document = \"We are learning tokenization in NLP\"\n",
        "word_tokenize(document) # OR use following function\n",
        "#document.split(' ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzTdZIXLupV6",
        "outputId": "3cbbdad0-9c3e-4a04-cfe9-21f4d8a0e654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['We', 'are', 'learning', 'tokenization', 'in', 'NLP']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(document)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gk62XDe9LPHm",
        "outputId": "91d0367e-4151-4d77-8f92-659c9be7add4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can't do word tokenization directly on paragraph. \\n represents new line in paragraph. For that Sentence tokenization need to be done."
      ],
      "metadata": {
        "id": "R21HHLW_wgQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Sentence Tokenization\n",
        "sent = nltk.sent_tokenize(para)"
      ],
      "metadata": {
        "id": "AlwkfvV5wM2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent # Every sentence is separated by comma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TR_NNDkLZyj",
        "outputId": "73e0ce94-9618-4a06-9d4a-c795eed84fd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['— Tensor and Tensorflow: A powerful combo 💪\\nThe Google Brain team developed an advanced AI framework named Tensorflow years back.',\n",
              " 'After that, Google designed its own processing unit named Tensor Processing Unit or TPU to perform more efficiently with the Tensorflow.',\n",
              " 'The invention of TPU was a revolution in AI that has significantly expedited the training of huge machine learning models with millions (or, billions) of parameters.',\n",
              " 'Nevertheless, that technology could not be used in low-power devices such as smartphones in Edge AI.',\n",
              " 'The entrance of Google into the AI chip manufacturing club for low-power devices can be the next revolution in this industry.',\n",
              " 'Many companies such as FogHorn and BlinkAI are working in Edge AI using currently existing AI chips in the market.',\n",
              " 'However, the efficacy that Google can create by the combination of TensorFlow and Tensor will be game-changing.',\n",
              " 'Welcome to the club, Google!',\n",
              " '— Tensor is an AI chip designed by AI!',\n",
              " '😲\\nIsn’t that cool?',\n",
              " 'The story is started from an article published in Nature titles “A graph placement methodology for fast chip design”.',\n",
              " 'To design a processing chip, there is a crucial step referred to as “floor planning” where the engineering team must place a large number of components such that a series of physical requirements including power consumption and performance get satisfied.',\n",
              " 'I don’t go further into its details as I am also not an expert in hardware engineering.',\n",
              " 'However, when you have a large series of choices to make with a series of constraints AI can kick in.',\n",
              " 'You may remember how the AlphaGo project defeated a professional human Go player.',\n",
              " 'This is exactly the same.',\n",
              " 'Tensor is the real outcome of this project that is a new milestone in the AI industry.',\n",
              " 'Kudos, Google!',\n",
              " '— Tensor helps us build ethical AI.',\n",
              " '💡\\nThis is a double-edged sword statement.',\n",
              " 'Ethical AI has various aspects from data privacy to AI for all.',\n",
              " 'Tensor helps many users have the opportunity to try the latest AI advancement while they have no concern about their privacy.',\n",
              " 'Why?',\n",
              " 'Because the AI engine is running on the chip, and no data is sent to the cloud for further computation.',\n",
              " 'On the other hand, the more tightly Google binds AI software and hardware, the harder it will be for other companies to compete.',\n",
              " 'I don’t want to see days that other companies can not even compete on performing AI inference, i.e., compete on using AI.',\n",
              " 'We almost lost the game of model training to giant tech companies.',\n",
              " 'It would be a nightmare if we lose the game on AI inference to them as well.',\n",
              " 'That is why I believe “Tensor helps us build ethical AI” is a double-edged sword.']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(sent) # length is 29 sentences i.e. 29 documents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTs5l5iUxRii",
        "outputId": "52202478-d2fa-4883-ebaf-8beb4ac4f29a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent[0] # shows first document"
      ],
      "metadata": {
        "id": "kCVEkKQ6xUOh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "eb323486-7a74-4b58-ba9e-e3fc03b8288f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'— Tensor and Tensorflow: A powerful combo 💪\\nThe Google Brain team developed an advanced AI framework named Tensorflow years back.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Text Cleaning - remove unnecessary things - punctuation marks, symbols, emojis, etc. using sub()\n",
        "# Text normalization - convert each word in lower case\n",
        "#  sub() returns a string where all matching occurrences of the specified pattern are replaced by the replace string.\n",
        "corpus = []\n",
        "\n",
        "for i in range(len(sent)):\n",
        "  txt = re.sub('[^a-zA-Z]',' ',sent[i])# except a-zA-Z remove everything from each sentence\n",
        "  txt = txt.lower()\n",
        "  corpus.append(txt)"
      ],
      "metadata": {
        "id": "7WcF0Z4yxkq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "id": "X46V7CTQzZHT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66b8d2cc-8f2d-4c75-fcf1-463f20515aeb",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['  tensor and tensorflow  a powerful combo   the google brain team developed an advanced ai framework named tensorflow years back ',\n",
              " 'after that  google designed its own processing unit named tensor processing unit or tpu to perform more efficiently with the tensorflow ',\n",
              " 'the invention of tpu was a revolution in ai that has significantly expedited the training of huge machine learning models with millions  or  billions  of parameters ',\n",
              " 'nevertheless  that technology could not be used in low power devices such as smartphones in edge ai ',\n",
              " 'the entrance of google into the ai chip manufacturing club for low power devices can be the next revolution in this industry ',\n",
              " 'many companies such as foghorn and blinkai are working in edge ai using currently existing ai chips in the market ',\n",
              " 'however  the efficacy that google can create by the combination of tensorflow and tensor will be game changing ',\n",
              " 'welcome to the club  google ',\n",
              " '  tensor is an ai chip designed by ai ',\n",
              " '  isn t that cool ',\n",
              " 'the story is started from an article published in nature titles  a graph placement methodology for fast chip design  ',\n",
              " 'to design a processing chip  there is a crucial step referred to as  floor planning  where the engineering team must place a large number of components such that a series of physical requirements including power consumption and performance get satisfied ',\n",
              " 'i don t go further into its details as i am also not an expert in hardware engineering ',\n",
              " 'however  when you have a large series of choices to make with a series of constraints ai can kick in ',\n",
              " 'you may remember how the alphago project defeated a professional human go player ',\n",
              " 'this is exactly the same ',\n",
              " 'tensor is the real outcome of this project that is a new milestone in the ai industry ',\n",
              " 'kudos  google ',\n",
              " '  tensor helps us build ethical ai ',\n",
              " '  this is a double edged sword statement ',\n",
              " 'ethical ai has various aspects from data privacy to ai for all ',\n",
              " 'tensor helps many users have the opportunity to try the latest ai advancement while they have no concern about their privacy ',\n",
              " 'why ',\n",
              " 'because the ai engine is running on the chip  and no data is sent to the cloud for further computation ',\n",
              " 'on the other hand  the more tightly google binds ai software and hardware  the harder it will be for other companies to compete ',\n",
              " 'i don t want to see days that other companies can not even compete on performing ai inference  i e   compete on using ai ',\n",
              " 'we almost lost the game of model training to giant tech companies ',\n",
              " 'it would be a nightmare if we lose the game on ai inference to them as well ',\n",
              " 'that is why i believe  tensor helps us build ethical ai  is a double edged sword ']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now we can perform stemming and lemmatization\n",
        "#Stemming\n",
        "stemmer = PorterStemmer()"
      ],
      "metadata": {
        "id": "j7oM9eB4zali"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer.stem('goes')"
      ],
      "metadata": {
        "id": "CuXSa2pJzs66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "0c5aade2-87c5-4f4b-a697-82461eff818e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'goe'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer.stem('argued')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ifF2uMjGMXvs",
        "outputId": "d124a0ad-33f1-4a55-db5b-527b4d876d52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'argu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer.stem('historically')"
      ],
      "metadata": {
        "id": "aC9YB6div21m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "f0c3988d-c82f-4b78-88a3-9191abae7e2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'histor'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer.stem('finally')"
      ],
      "metadata": {
        "id": "yxOMvLWtz5JX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d8d3d764-18dd-4b05-fb18-2b1c51b6d68e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'final'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer.stem(\"developed\")"
      ],
      "metadata": {
        "id": "EmRETLHXTOTE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "374e61e0-ed1d-46f6-f7a6-6dd954de2787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'develop'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCNm-F-UMx7B",
        "outputId": "3c4f0d38-d728-43fb-879d-d9e7cbb9a0b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# display tokenized word\n",
        "for i in corpus:\n",
        "  words = nltk.word_tokenize(i)\n",
        "  for i in words:\n",
        "    print(i)\n",
        "  # we get separate list for each sentence"
      ],
      "metadata": {
        "id": "25WelZkhz7-x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be82d4ca-e879-47e2-915c-b0317842fcf0",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor\n",
            "and\n",
            "tensorflow\n",
            "a\n",
            "powerful\n",
            "combo\n",
            "the\n",
            "google\n",
            "brain\n",
            "team\n",
            "developed\n",
            "an\n",
            "advanced\n",
            "ai\n",
            "framework\n",
            "named\n",
            "tensorflow\n",
            "years\n",
            "back\n",
            "after\n",
            "that\n",
            "google\n",
            "designed\n",
            "its\n",
            "own\n",
            "processing\n",
            "unit\n",
            "named\n",
            "tensor\n",
            "processing\n",
            "unit\n",
            "or\n",
            "tpu\n",
            "to\n",
            "perform\n",
            "more\n",
            "efficiently\n",
            "with\n",
            "the\n",
            "tensorflow\n",
            "the\n",
            "invention\n",
            "of\n",
            "tpu\n",
            "was\n",
            "a\n",
            "revolution\n",
            "in\n",
            "ai\n",
            "that\n",
            "has\n",
            "significantly\n",
            "expedited\n",
            "the\n",
            "training\n",
            "of\n",
            "huge\n",
            "machine\n",
            "learning\n",
            "models\n",
            "with\n",
            "millions\n",
            "or\n",
            "billions\n",
            "of\n",
            "parameters\n",
            "nevertheless\n",
            "that\n",
            "technology\n",
            "could\n",
            "not\n",
            "be\n",
            "used\n",
            "in\n",
            "low\n",
            "power\n",
            "devices\n",
            "such\n",
            "as\n",
            "smartphones\n",
            "in\n",
            "edge\n",
            "ai\n",
            "the\n",
            "entrance\n",
            "of\n",
            "google\n",
            "into\n",
            "the\n",
            "ai\n",
            "chip\n",
            "manufacturing\n",
            "club\n",
            "for\n",
            "low\n",
            "power\n",
            "devices\n",
            "can\n",
            "be\n",
            "the\n",
            "next\n",
            "revolution\n",
            "in\n",
            "this\n",
            "industry\n",
            "many\n",
            "companies\n",
            "such\n",
            "as\n",
            "foghorn\n",
            "and\n",
            "blinkai\n",
            "are\n",
            "working\n",
            "in\n",
            "edge\n",
            "ai\n",
            "using\n",
            "currently\n",
            "existing\n",
            "ai\n",
            "chips\n",
            "in\n",
            "the\n",
            "market\n",
            "however\n",
            "the\n",
            "efficacy\n",
            "that\n",
            "google\n",
            "can\n",
            "create\n",
            "by\n",
            "the\n",
            "combination\n",
            "of\n",
            "tensorflow\n",
            "and\n",
            "tensor\n",
            "will\n",
            "be\n",
            "game\n",
            "changing\n",
            "welcome\n",
            "to\n",
            "the\n",
            "club\n",
            "google\n",
            "tensor\n",
            "is\n",
            "an\n",
            "ai\n",
            "chip\n",
            "designed\n",
            "by\n",
            "ai\n",
            "isn\n",
            "t\n",
            "that\n",
            "cool\n",
            "the\n",
            "story\n",
            "is\n",
            "started\n",
            "from\n",
            "an\n",
            "article\n",
            "published\n",
            "in\n",
            "nature\n",
            "titles\n",
            "a\n",
            "graph\n",
            "placement\n",
            "methodology\n",
            "for\n",
            "fast\n",
            "chip\n",
            "design\n",
            "to\n",
            "design\n",
            "a\n",
            "processing\n",
            "chip\n",
            "there\n",
            "is\n",
            "a\n",
            "crucial\n",
            "step\n",
            "referred\n",
            "to\n",
            "as\n",
            "floor\n",
            "planning\n",
            "where\n",
            "the\n",
            "engineering\n",
            "team\n",
            "must\n",
            "place\n",
            "a\n",
            "large\n",
            "number\n",
            "of\n",
            "components\n",
            "such\n",
            "that\n",
            "a\n",
            "series\n",
            "of\n",
            "physical\n",
            "requirements\n",
            "including\n",
            "power\n",
            "consumption\n",
            "and\n",
            "performance\n",
            "get\n",
            "satisfied\n",
            "i\n",
            "don\n",
            "t\n",
            "go\n",
            "further\n",
            "into\n",
            "its\n",
            "details\n",
            "as\n",
            "i\n",
            "am\n",
            "also\n",
            "not\n",
            "an\n",
            "expert\n",
            "in\n",
            "hardware\n",
            "engineering\n",
            "however\n",
            "when\n",
            "you\n",
            "have\n",
            "a\n",
            "large\n",
            "series\n",
            "of\n",
            "choices\n",
            "to\n",
            "make\n",
            "with\n",
            "a\n",
            "series\n",
            "of\n",
            "constraints\n",
            "ai\n",
            "can\n",
            "kick\n",
            "in\n",
            "you\n",
            "may\n",
            "remember\n",
            "how\n",
            "the\n",
            "alphago\n",
            "project\n",
            "defeated\n",
            "a\n",
            "professional\n",
            "human\n",
            "go\n",
            "player\n",
            "this\n",
            "is\n",
            "exactly\n",
            "the\n",
            "same\n",
            "tensor\n",
            "is\n",
            "the\n",
            "real\n",
            "outcome\n",
            "of\n",
            "this\n",
            "project\n",
            "that\n",
            "is\n",
            "a\n",
            "new\n",
            "milestone\n",
            "in\n",
            "the\n",
            "ai\n",
            "industry\n",
            "kudos\n",
            "google\n",
            "tensor\n",
            "helps\n",
            "us\n",
            "build\n",
            "ethical\n",
            "ai\n",
            "this\n",
            "is\n",
            "a\n",
            "double\n",
            "edged\n",
            "sword\n",
            "statement\n",
            "ethical\n",
            "ai\n",
            "has\n",
            "various\n",
            "aspects\n",
            "from\n",
            "data\n",
            "privacy\n",
            "to\n",
            "ai\n",
            "for\n",
            "all\n",
            "tensor\n",
            "helps\n",
            "many\n",
            "users\n",
            "have\n",
            "the\n",
            "opportunity\n",
            "to\n",
            "try\n",
            "the\n",
            "latest\n",
            "ai\n",
            "advancement\n",
            "while\n",
            "they\n",
            "have\n",
            "no\n",
            "concern\n",
            "about\n",
            "their\n",
            "privacy\n",
            "why\n",
            "because\n",
            "the\n",
            "ai\n",
            "engine\n",
            "is\n",
            "running\n",
            "on\n",
            "the\n",
            "chip\n",
            "and\n",
            "no\n",
            "data\n",
            "is\n",
            "sent\n",
            "to\n",
            "the\n",
            "cloud\n",
            "for\n",
            "further\n",
            "computation\n",
            "on\n",
            "the\n",
            "other\n",
            "hand\n",
            "the\n",
            "more\n",
            "tightly\n",
            "google\n",
            "binds\n",
            "ai\n",
            "software\n",
            "and\n",
            "hardware\n",
            "the\n",
            "harder\n",
            "it\n",
            "will\n",
            "be\n",
            "for\n",
            "other\n",
            "companies\n",
            "to\n",
            "compete\n",
            "i\n",
            "don\n",
            "t\n",
            "want\n",
            "to\n",
            "see\n",
            "days\n",
            "that\n",
            "other\n",
            "companies\n",
            "can\n",
            "not\n",
            "even\n",
            "compete\n",
            "on\n",
            "performing\n",
            "ai\n",
            "inference\n",
            "i\n",
            "e\n",
            "compete\n",
            "on\n",
            "using\n",
            "ai\n",
            "we\n",
            "almost\n",
            "lost\n",
            "the\n",
            "game\n",
            "of\n",
            "model\n",
            "training\n",
            "to\n",
            "giant\n",
            "tech\n",
            "companies\n",
            "it\n",
            "would\n",
            "be\n",
            "a\n",
            "nightmare\n",
            "if\n",
            "we\n",
            "lose\n",
            "the\n",
            "game\n",
            "on\n",
            "ai\n",
            "inference\n",
            "to\n",
            "them\n",
            "as\n",
            "well\n",
            "that\n",
            "is\n",
            "why\n",
            "i\n",
            "believe\n",
            "tensor\n",
            "helps\n",
            "us\n",
            "build\n",
            "ethical\n",
            "ai\n",
            "is\n",
            "a\n",
            "double\n",
            "edged\n",
            "sword\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Tokenization, stemming and stop word removal\n",
        "\n",
        "for i in corpus:\n",
        "  words = word_tokenize(i) # for each sentence in corpus perform word tokenization\n",
        "  for i in words: # for each unique value inside word\n",
        "    if i not in stopwords.words('english'): # will check words in stopwords from set of english stopwords\n",
        "      print(stemmer.stem(i)) # the words whch are not present in stopwords set print by performing stemming using stem() function.\n",
        "      # powerful - power, google-googl ... doesn't make sense"
      ],
      "metadata": {
        "id": "NiYslxcB0h7x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a247c5c8-1665-453d-a217-bcc8ece714a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor\n",
            "tensorflow\n",
            "power\n",
            "combo\n",
            "googl\n",
            "brain\n",
            "team\n",
            "develop\n",
            "advanc\n",
            "ai\n",
            "framework\n",
            "name\n",
            "tensorflow\n",
            "year\n",
            "back\n",
            "googl\n",
            "design\n",
            "process\n",
            "unit\n",
            "name\n",
            "tensor\n",
            "process\n",
            "unit\n",
            "tpu\n",
            "perform\n",
            "effici\n",
            "tensorflow\n",
            "invent\n",
            "tpu\n",
            "revolut\n",
            "ai\n",
            "significantli\n",
            "expedit\n",
            "train\n",
            "huge\n",
            "machin\n",
            "learn\n",
            "model\n",
            "million\n",
            "billion\n",
            "paramet\n",
            "nevertheless\n",
            "technolog\n",
            "could\n",
            "use\n",
            "low\n",
            "power\n",
            "devic\n",
            "smartphon\n",
            "edg\n",
            "ai\n",
            "entranc\n",
            "googl\n",
            "ai\n",
            "chip\n",
            "manufactur\n",
            "club\n",
            "low\n",
            "power\n",
            "devic\n",
            "next\n",
            "revolut\n",
            "industri\n",
            "mani\n",
            "compani\n",
            "foghorn\n",
            "blinkai\n",
            "work\n",
            "edg\n",
            "ai\n",
            "use\n",
            "current\n",
            "exist\n",
            "ai\n",
            "chip\n",
            "market\n",
            "howev\n",
            "efficaci\n",
            "googl\n",
            "creat\n",
            "combin\n",
            "tensorflow\n",
            "tensor\n",
            "game\n",
            "chang\n",
            "welcom\n",
            "club\n",
            "googl\n",
            "tensor\n",
            "ai\n",
            "chip\n",
            "design\n",
            "ai\n",
            "cool\n",
            "stori\n",
            "start\n",
            "articl\n",
            "publish\n",
            "natur\n",
            "titl\n",
            "graph\n",
            "placement\n",
            "methodolog\n",
            "fast\n",
            "chip\n",
            "design\n",
            "design\n",
            "process\n",
            "chip\n",
            "crucial\n",
            "step\n",
            "refer\n",
            "floor\n",
            "plan\n",
            "engin\n",
            "team\n",
            "must\n",
            "place\n",
            "larg\n",
            "number\n",
            "compon\n",
            "seri\n",
            "physic\n",
            "requir\n",
            "includ\n",
            "power\n",
            "consumpt\n",
            "perform\n",
            "get\n",
            "satisfi\n",
            "go\n",
            "detail\n",
            "also\n",
            "expert\n",
            "hardwar\n",
            "engin\n",
            "howev\n",
            "larg\n",
            "seri\n",
            "choic\n",
            "make\n",
            "seri\n",
            "constraint\n",
            "ai\n",
            "kick\n",
            "may\n",
            "rememb\n",
            "alphago\n",
            "project\n",
            "defeat\n",
            "profession\n",
            "human\n",
            "go\n",
            "player\n",
            "exactli\n",
            "tensor\n",
            "real\n",
            "outcom\n",
            "project\n",
            "new\n",
            "mileston\n",
            "ai\n",
            "industri\n",
            "kudo\n",
            "googl\n",
            "tensor\n",
            "help\n",
            "us\n",
            "build\n",
            "ethic\n",
            "ai\n",
            "doubl\n",
            "edg\n",
            "sword\n",
            "statement\n",
            "ethic\n",
            "ai\n",
            "variou\n",
            "aspect\n",
            "data\n",
            "privaci\n",
            "ai\n",
            "tensor\n",
            "help\n",
            "mani\n",
            "user\n",
            "opportun\n",
            "tri\n",
            "latest\n",
            "ai\n",
            "advanc\n",
            "concern\n",
            "privaci\n",
            "ai\n",
            "engin\n",
            "run\n",
            "chip\n",
            "data\n",
            "sent\n",
            "cloud\n",
            "comput\n",
            "hand\n",
            "tightli\n",
            "googl\n",
            "bind\n",
            "ai\n",
            "softwar\n",
            "hardwar\n",
            "harder\n",
            "compani\n",
            "compet\n",
            "want\n",
            "see\n",
            "day\n",
            "compani\n",
            "even\n",
            "compet\n",
            "perform\n",
            "ai\n",
            "infer\n",
            "e\n",
            "compet\n",
            "use\n",
            "ai\n",
            "almost\n",
            "lost\n",
            "game\n",
            "model\n",
            "train\n",
            "giant\n",
            "tech\n",
            "compani\n",
            "would\n",
            "nightmar\n",
            "lose\n",
            "game\n",
            "ai\n",
            "infer\n",
            "well\n",
            "believ\n",
            "tensor\n",
            "help\n",
            "us\n",
            "build\n",
            "ethic\n",
            "ai\n",
            "doubl\n",
            "edg\n",
            "sword\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatization\n",
        "lemma = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "tfNvuBlu0bpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemma.lemmatize('google')"
      ],
      "metadata": {
        "id": "PckAPFjq3GjP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "5b58bd68-1f82-4b91-b8b8-c7a0f9679893"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'google'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemma.lemmatize('historical')"
      ],
      "metadata": {
        "id": "3lg6oH5M3KS8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "8d9f4e8c-474b-4e83-ed37-0f7bc3298485"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'historical'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemma.lemmatize('coming')"
      ],
      "metadata": {
        "id": "03PYxv1G3s9g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "5284b07b-9e7f-4073-ac25-3e69a4e3c236"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'coming'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in corpus:\n",
        "  words = word_tokenize(i)\n",
        "  for i in words:\n",
        "    if i not in stopwords.words('english'):\n",
        "      print(lemma.lemmatize(i))\n",
        "      #proper google, powerful.. meaningful words are returned by lemmatization\n"
      ],
      "metadata": {
        "id": "tfc9_BWD3vHt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8dc491d-7a68-4e30-f803-56f1df89ac89",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor\n",
            "tensorflow\n",
            "powerful\n",
            "combo\n",
            "google\n",
            "brain\n",
            "team\n",
            "developed\n",
            "advanced\n",
            "ai\n",
            "framework\n",
            "named\n",
            "tensorflow\n",
            "year\n",
            "back\n",
            "google\n",
            "designed\n",
            "processing\n",
            "unit\n",
            "named\n",
            "tensor\n",
            "processing\n",
            "unit\n",
            "tpu\n",
            "perform\n",
            "efficiently\n",
            "tensorflow\n",
            "invention\n",
            "tpu\n",
            "revolution\n",
            "ai\n",
            "significantly\n",
            "expedited\n",
            "training\n",
            "huge\n",
            "machine\n",
            "learning\n",
            "model\n",
            "million\n",
            "billion\n",
            "parameter\n",
            "nevertheless\n",
            "technology\n",
            "could\n",
            "used\n",
            "low\n",
            "power\n",
            "device\n",
            "smartphones\n",
            "edge\n",
            "ai\n",
            "entrance\n",
            "google\n",
            "ai\n",
            "chip\n",
            "manufacturing\n",
            "club\n",
            "low\n",
            "power\n",
            "device\n",
            "next\n",
            "revolution\n",
            "industry\n",
            "many\n",
            "company\n",
            "foghorn\n",
            "blinkai\n",
            "working\n",
            "edge\n",
            "ai\n",
            "using\n",
            "currently\n",
            "existing\n",
            "ai\n",
            "chip\n",
            "market\n",
            "however\n",
            "efficacy\n",
            "google\n",
            "create\n",
            "combination\n",
            "tensorflow\n",
            "tensor\n",
            "game\n",
            "changing\n",
            "welcome\n",
            "club\n",
            "google\n",
            "tensor\n",
            "ai\n",
            "chip\n",
            "designed\n",
            "ai\n",
            "cool\n",
            "story\n",
            "started\n",
            "article\n",
            "published\n",
            "nature\n",
            "title\n",
            "graph\n",
            "placement\n",
            "methodology\n",
            "fast\n",
            "chip\n",
            "design\n",
            "design\n",
            "processing\n",
            "chip\n",
            "crucial\n",
            "step\n",
            "referred\n",
            "floor\n",
            "planning\n",
            "engineering\n",
            "team\n",
            "must\n",
            "place\n",
            "large\n",
            "number\n",
            "component\n",
            "series\n",
            "physical\n",
            "requirement\n",
            "including\n",
            "power\n",
            "consumption\n",
            "performance\n",
            "get\n",
            "satisfied\n",
            "go\n",
            "detail\n",
            "also\n",
            "expert\n",
            "hardware\n",
            "engineering\n",
            "however\n",
            "large\n",
            "series\n",
            "choice\n",
            "make\n",
            "series\n",
            "constraint\n",
            "ai\n",
            "kick\n",
            "may\n",
            "remember\n",
            "alphago\n",
            "project\n",
            "defeated\n",
            "professional\n",
            "human\n",
            "go\n",
            "player\n",
            "exactly\n",
            "tensor\n",
            "real\n",
            "outcome\n",
            "project\n",
            "new\n",
            "milestone\n",
            "ai\n",
            "industry\n",
            "kudos\n",
            "google\n",
            "tensor\n",
            "help\n",
            "u\n",
            "build\n",
            "ethical\n",
            "ai\n",
            "double\n",
            "edged\n",
            "sword\n",
            "statement\n",
            "ethical\n",
            "ai\n",
            "various\n",
            "aspect\n",
            "data\n",
            "privacy\n",
            "ai\n",
            "tensor\n",
            "help\n",
            "many\n",
            "user\n",
            "opportunity\n",
            "try\n",
            "latest\n",
            "ai\n",
            "advancement\n",
            "concern\n",
            "privacy\n",
            "ai\n",
            "engine\n",
            "running\n",
            "chip\n",
            "data\n",
            "sent\n",
            "cloud\n",
            "computation\n",
            "hand\n",
            "tightly\n",
            "google\n",
            "bind\n",
            "ai\n",
            "software\n",
            "hardware\n",
            "harder\n",
            "company\n",
            "compete\n",
            "want\n",
            "see\n",
            "day\n",
            "company\n",
            "even\n",
            "compete\n",
            "performing\n",
            "ai\n",
            "inference\n",
            "e\n",
            "compete\n",
            "using\n",
            "ai\n",
            "almost\n",
            "lost\n",
            "game\n",
            "model\n",
            "training\n",
            "giant\n",
            "tech\n",
            "company\n",
            "would\n",
            "nightmare\n",
            "lose\n",
            "game\n",
            "ai\n",
            "inference\n",
            "well\n",
            "believe\n",
            "tensor\n",
            "help\n",
            "u\n",
            "build\n",
            "ethical\n",
            "ai\n",
            "double\n",
            "edged\n",
            "sword\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Extraction**"
      ],
      "metadata": {
        "id": "cKgt3gR64S4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert text data to BoW (Bag of Words) or TFIDF (Term Frequency - Inverse Document Frequency)\n",
        "# CountVectorizer - for BoW, TfidfVectorizer - for TFIDF\n",
        "#import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n"
      ],
      "metadata": {
        "id": "HXnaCe-e4HG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cv = CountVectorizer() # BoW - frequency will be displayed\n",
        "# Bag of Words (BoW) simply counts the frequency of words in a document.\n",
        "cv = CountVectorizer(binary=True) # only binary weight will be displayed i.e. present or not\n",
        "\n",
        "x = cv.fit_transform(corpus) #counts no. of sentences, checks unique words in it, finds frequency of words\n",
        "x\n",
        "cv.vocabulary_ # following words are taken as columns, no. represents index of each word\n",
        "#print(max(cv.vocabulary_))"
      ],
      "metadata": {
        "id": "p-VCcUWU4l1K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "5daa500e-762a-4e94-9326-1e83109731f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'tensor': 180,\n",
              " 'and': 11,\n",
              " 'tensorflow': 181,\n",
              " 'powerful': 151,\n",
              " 'combo': 34,\n",
              " 'the': 183,\n",
              " 'google': 81,\n",
              " 'brain': 23,\n",
              " 'team': 177,\n",
              " 'developed': 53,\n",
              " 'an': 10,\n",
              " 'advanced': 1,\n",
              " 'ai': 4,\n",
              " 'framework': 74,\n",
              " 'named': 125,\n",
              " 'years': 214,\n",
              " 'back': 16,\n",
              " 'after': 3,\n",
              " 'that': 182,\n",
              " 'designed': 51,\n",
              " 'its': 103,\n",
              " 'own': 140,\n",
              " 'processing': 153,\n",
              " 'unit': 195,\n",
              " 'or': 137,\n",
              " 'tpu': 192,\n",
              " 'to': 191,\n",
              " 'perform': 142,\n",
              " 'more': 123,\n",
              " 'efficiently': 60,\n",
              " 'with': 211,\n",
              " 'invention': 99,\n",
              " 'of': 134,\n",
              " 'was': 202,\n",
              " 'revolution': 161,\n",
              " 'in': 94,\n",
              " 'has': 86,\n",
              " 'significantly': 168,\n",
              " 'expedited': 68,\n",
              " 'training': 193,\n",
              " 'huge': 91,\n",
              " 'machine': 112,\n",
              " 'learning': 108,\n",
              " 'models': 122,\n",
              " 'millions': 120,\n",
              " 'billions': 20,\n",
              " 'parameters': 141,\n",
              " 'nevertheless': 127,\n",
              " 'technology': 179,\n",
              " 'could': 43,\n",
              " 'not': 132,\n",
              " 'be': 17,\n",
              " 'used': 197,\n",
              " 'low': 111,\n",
              " 'power': 150,\n",
              " 'devices': 54,\n",
              " 'such': 175,\n",
              " 'as': 14,\n",
              " 'smartphones': 169,\n",
              " 'edge': 57,\n",
              " 'entrance': 63,\n",
              " 'into': 98,\n",
              " 'chip': 28,\n",
              " 'manufacturing': 114,\n",
              " 'club': 32,\n",
              " 'for': 73,\n",
              " 'can': 26,\n",
              " 'next': 129,\n",
              " 'this': 188,\n",
              " 'industry': 96,\n",
              " 'many': 115,\n",
              " 'companies': 35,\n",
              " 'foghorn': 72,\n",
              " 'blinkai': 22,\n",
              " 'are': 12,\n",
              " 'working': 212,\n",
              " 'using': 199,\n",
              " 'currently': 46,\n",
              " 'existing': 67,\n",
              " 'chips': 29,\n",
              " 'market': 116,\n",
              " 'however': 90,\n",
              " 'efficacy': 59,\n",
              " 'create': 44,\n",
              " 'by': 25,\n",
              " 'combination': 33,\n",
              " 'will': 210,\n",
              " 'game': 77,\n",
              " 'changing': 27,\n",
              " 'welcome': 204,\n",
              " 'is': 100,\n",
              " 'isn': 101,\n",
              " 'cool': 42,\n",
              " 'story': 174,\n",
              " 'started': 171,\n",
              " 'from': 75,\n",
              " 'article': 13,\n",
              " 'published': 156,\n",
              " 'nature': 126,\n",
              " 'titles': 190,\n",
              " 'graph': 82,\n",
              " 'placement': 147,\n",
              " 'methodology': 118,\n",
              " 'fast': 70,\n",
              " 'design': 50,\n",
              " 'there': 186,\n",
              " 'crucial': 45,\n",
              " 'step': 173,\n",
              " 'referred': 158,\n",
              " 'floor': 71,\n",
              " 'planning': 148,\n",
              " 'where': 207,\n",
              " 'engineering': 62,\n",
              " 'must': 124,\n",
              " 'place': 146,\n",
              " 'large': 106,\n",
              " 'number': 133,\n",
              " 'components': 37,\n",
              " 'series': 167,\n",
              " 'physical': 145,\n",
              " 'requirements': 160,\n",
              " 'including': 95,\n",
              " 'consumption': 41,\n",
              " 'performance': 143,\n",
              " 'get': 78,\n",
              " 'satisfied': 164,\n",
              " 'don': 55,\n",
              " 'go': 80,\n",
              " 'further': 76,\n",
              " 'details': 52,\n",
              " 'am': 9,\n",
              " 'also': 8,\n",
              " 'expert': 69,\n",
              " 'hardware': 85,\n",
              " 'when': 206,\n",
              " 'you': 215,\n",
              " 'have': 87,\n",
              " 'choices': 30,\n",
              " 'make': 113,\n",
              " 'constraints': 40,\n",
              " 'kick': 104,\n",
              " 'may': 117,\n",
              " 'remember': 159,\n",
              " 'how': 89,\n",
              " 'alphago': 7,\n",
              " 'project': 155,\n",
              " 'defeated': 49,\n",
              " 'professional': 154,\n",
              " 'human': 92,\n",
              " 'player': 149,\n",
              " 'exactly': 66,\n",
              " 'same': 163,\n",
              " 'real': 157,\n",
              " 'outcome': 139,\n",
              " 'new': 128,\n",
              " 'milestone': 119,\n",
              " 'kudos': 105,\n",
              " 'helps': 88,\n",
              " 'us': 196,\n",
              " 'build': 24,\n",
              " 'ethical': 64,\n",
              " 'double': 56,\n",
              " 'edged': 58,\n",
              " 'sword': 176,\n",
              " 'statement': 172,\n",
              " 'various': 200,\n",
              " 'aspects': 15,\n",
              " 'data': 47,\n",
              " 'privacy': 152,\n",
              " 'all': 5,\n",
              " 'users': 198,\n",
              " 'opportunity': 136,\n",
              " 'try': 194,\n",
              " 'latest': 107,\n",
              " 'advancement': 2,\n",
              " 'while': 208,\n",
              " 'they': 187,\n",
              " 'no': 131,\n",
              " 'concern': 39,\n",
              " 'about': 0,\n",
              " 'their': 184,\n",
              " 'why': 209,\n",
              " 'because': 18,\n",
              " 'engine': 61,\n",
              " 'running': 162,\n",
              " 'on': 135,\n",
              " 'sent': 166,\n",
              " 'cloud': 31,\n",
              " 'computation': 38,\n",
              " 'other': 138,\n",
              " 'hand': 83,\n",
              " 'tightly': 189,\n",
              " 'binds': 21,\n",
              " 'software': 170,\n",
              " 'harder': 84,\n",
              " 'it': 102,\n",
              " 'compete': 36,\n",
              " 'want': 201,\n",
              " 'see': 165,\n",
              " 'days': 48,\n",
              " 'even': 65,\n",
              " 'performing': 144,\n",
              " 'inference': 97,\n",
              " 'we': 203,\n",
              " 'almost': 6,\n",
              " 'lost': 110,\n",
              " 'model': 121,\n",
              " 'giant': 79,\n",
              " 'tech': 178,\n",
              " 'would': 213,\n",
              " 'nightmare': 130,\n",
              " 'if': 93,\n",
              " 'lose': 109,\n",
              " 'them': 185,\n",
              " 'well': 205,\n",
              " 'believe': 19}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let us see what type of BoW it has created. BoW - gives frequency of term in document, Binary Weight - tells word is present or not\n",
        "# We can't directly print matrix x. so we need to convert it to array\n",
        "x[0].toarray() # BoW for 1st sentence,    'tensorflow': index is: 181. It occurred 2 times in 1st sentence. Check corpus[0]."
      ],
      "metadata": {
        "id": "wAtrx45p48nx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ef6003a-9798-4d52-d02d-565337d45c74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus[0] # for this sentence above BoW is created. Why does it contain more values than the no. of words in this sentence?\n",
        "\n",
        "# Column contains all unique words."
      ],
      "metadata": {
        "id": "ydLIAv07GHLW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "97b86778-097f-4975-ca51-d9a812f691ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'  tensor and tensorflow  a powerful combo   the google brain team developed an advanced ai framework named tensorflow years back '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert array into dataframe, DTM - Document Term Matrix\n",
        "x = pd.DataFrame(x.toarray(),columns=cv.get_feature_names_out())\n",
        "x\n",
        "# for 'advanced' word index was 1 so it is present at colummn index no. 1\n",
        "# in 5th document word 'ai' is occuring for 2 times.\n",
        "# BoW - gives you frequency\n",
        "# Binary weights - tells whether word is present or not\n",
        "# If you don't want to print frequency in dataframe, keep binary=True in 'cv = CountVectonizer(binary=True)'"
      ],
      "metadata": {
        "id": "6eKJYHccGK32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7cfdaf21-93c1-4d0e-b516-e78b1d371d7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    about  advanced  advancement  after  ai  all  almost  alphago  also  am  \\\n",
              "0       0         1            0      0   1    0       0        0     0   0   \n",
              "1       0         0            0      1   0    0       0        0     0   0   \n",
              "2       0         0            0      0   1    0       0        0     0   0   \n",
              "3       0         0            0      0   1    0       0        0     0   0   \n",
              "4       0         0            0      0   1    0       0        0     0   0   \n",
              "5       0         0            0      0   1    0       0        0     0   0   \n",
              "6       0         0            0      0   0    0       0        0     0   0   \n",
              "7       0         0            0      0   0    0       0        0     0   0   \n",
              "8       0         0            0      0   1    0       0        0     0   0   \n",
              "9       0         0            0      0   0    0       0        0     0   0   \n",
              "10      0         0            0      0   0    0       0        0     0   0   \n",
              "11      0         0            0      0   0    0       0        0     0   0   \n",
              "12      0         0            0      0   0    0       0        0     1   1   \n",
              "13      0         0            0      0   1    0       0        0     0   0   \n",
              "14      0         0            0      0   0    0       0        1     0   0   \n",
              "15      0         0            0      0   0    0       0        0     0   0   \n",
              "16      0         0            0      0   1    0       0        0     0   0   \n",
              "17      0         0            0      0   0    0       0        0     0   0   \n",
              "18      0         0            0      0   1    0       0        0     0   0   \n",
              "19      0         0            0      0   0    0       0        0     0   0   \n",
              "20      0         0            0      0   1    1       0        0     0   0   \n",
              "21      1         0            1      0   1    0       0        0     0   0   \n",
              "22      0         0            0      0   0    0       0        0     0   0   \n",
              "23      0         0            0      0   1    0       0        0     0   0   \n",
              "24      0         0            0      0   1    0       0        0     0   0   \n",
              "25      0         0            0      0   1    0       0        0     0   0   \n",
              "26      0         0            0      0   0    0       1        0     0   0   \n",
              "27      0         0            0      0   1    0       0        0     0   0   \n",
              "28      0         0            0      0   1    0       0        0     0   0   \n",
              "\n",
              "    ...  when  where  while  why  will  with  working  would  years  you  \n",
              "0   ...     0      0      0    0     0     0        0      0      1    0  \n",
              "1   ...     0      0      0    0     0     1        0      0      0    0  \n",
              "2   ...     0      0      0    0     0     1        0      0      0    0  \n",
              "3   ...     0      0      0    0     0     0        0      0      0    0  \n",
              "4   ...     0      0      0    0     0     0        0      0      0    0  \n",
              "5   ...     0      0      0    0     0     0        1      0      0    0  \n",
              "6   ...     0      0      0    0     1     0        0      0      0    0  \n",
              "7   ...     0      0      0    0     0     0        0      0      0    0  \n",
              "8   ...     0      0      0    0     0     0        0      0      0    0  \n",
              "9   ...     0      0      0    0     0     0        0      0      0    0  \n",
              "10  ...     0      0      0    0     0     0        0      0      0    0  \n",
              "11  ...     0      1      0    0     0     0        0      0      0    0  \n",
              "12  ...     0      0      0    0     0     0        0      0      0    0  \n",
              "13  ...     1      0      0    0     0     1        0      0      0    1  \n",
              "14  ...     0      0      0    0     0     0        0      0      0    1  \n",
              "15  ...     0      0      0    0     0     0        0      0      0    0  \n",
              "16  ...     0      0      0    0     0     0        0      0      0    0  \n",
              "17  ...     0      0      0    0     0     0        0      0      0    0  \n",
              "18  ...     0      0      0    0     0     0        0      0      0    0  \n",
              "19  ...     0      0      0    0     0     0        0      0      0    0  \n",
              "20  ...     0      0      0    0     0     0        0      0      0    0  \n",
              "21  ...     0      0      1    0     0     0        0      0      0    0  \n",
              "22  ...     0      0      0    1     0     0        0      0      0    0  \n",
              "23  ...     0      0      0    0     0     0        0      0      0    0  \n",
              "24  ...     0      0      0    0     1     0        0      0      0    0  \n",
              "25  ...     0      0      0    0     0     0        0      0      0    0  \n",
              "26  ...     0      0      0    0     0     0        0      0      0    0  \n",
              "27  ...     0      0      0    0     0     0        0      1      0    0  \n",
              "28  ...     0      0      0    1     0     0        0      0      0    0  \n",
              "\n",
              "[29 rows x 216 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ff571a69-fc3c-4191-9ca2-c1dc81d110b0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>about</th>\n",
              "      <th>advanced</th>\n",
              "      <th>advancement</th>\n",
              "      <th>after</th>\n",
              "      <th>ai</th>\n",
              "      <th>all</th>\n",
              "      <th>almost</th>\n",
              "      <th>alphago</th>\n",
              "      <th>also</th>\n",
              "      <th>am</th>\n",
              "      <th>...</th>\n",
              "      <th>when</th>\n",
              "      <th>where</th>\n",
              "      <th>while</th>\n",
              "      <th>why</th>\n",
              "      <th>will</th>\n",
              "      <th>with</th>\n",
              "      <th>working</th>\n",
              "      <th>would</th>\n",
              "      <th>years</th>\n",
              "      <th>you</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29 rows × 216 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff571a69-fc3c-4191-9ca2-c1dc81d110b0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ff571a69-fc3c-4191-9ca2-c1dc81d110b0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ff571a69-fc3c-4191-9ca2-c1dc81d110b0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-25ac41ad-0cd8-4fa2-b22d-1b30441aeb76\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-25ac41ad-0cd8-4fa2-b22d-1b30441aeb76')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-25ac41ad-0cd8-4fa2-b22d-1b30441aeb76 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_140513c5-1e86-40d6-9c47-c5dfefd05a2b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('x')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_140513c5-1e86-40d6-9c47-c5dfefd05a2b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('x');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "x"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can start model building now. We have 216 columns i.e. 216 unique words are there.\n",
        "# 29 rows - 29 documents / sentences are there."
      ],
      "metadata": {
        "id": "WbqPtNmZMHh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TF-IDF**\n",
        "Term frequency works by looking at the frequency of a particular term you are concerned with relative to the document.\n",
        "\n",
        "Inverse document frequency looks at how common (or uncommon) a word is amongst the corpus.\n",
        "\n",
        "The highest scoring words of a document are the most relevant to that document.\n",
        "\n"
      ],
      "metadata": {
        "id": "rNxMU2gsNO8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf = TfidfVectorizer()\n",
        "x = tf.fit_transform(corpus)"
      ],
      "metadata": {
        "id": "jt9ZsrZ_G3QA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# in tf-idf we will see weightage not 0 and 1\n",
        "x.toarray()"
      ],
      "metadata": {
        "id": "wQDnJ6tANZwc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3c465d8-5f5d-4ad7-d956-e4beaff7fdf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.26420014, 0.        , ..., 0.        , 0.26420014,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.29867304, 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert it into dataframe\n",
        "x = pd.DataFrame(x.toarray(),columns = tf.get_feature_names_out()) #get_feature_names_out() - gives you list of unique words inside corpus\n",
        "x # here we are retaining information related to the frequency of words, TDM-Term Document Frequency"
      ],
      "metadata": {
        "id": "EUuJ3rXqNmyd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1b24f39d-91ec-4998-c937-bf3af24d5f40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       about  advanced  advancement     after        ai       all    almost  \\\n",
              "0   0.000000    0.2642     0.000000  0.000000  0.111720  0.000000  0.000000   \n",
              "1   0.000000    0.0000     0.000000  0.230918  0.000000  0.000000  0.000000   \n",
              "2   0.000000    0.0000     0.000000  0.000000  0.093004  0.000000  0.000000   \n",
              "3   0.000000    0.0000     0.000000  0.000000  0.120739  0.000000  0.000000   \n",
              "4   0.000000    0.0000     0.000000  0.000000  0.113623  0.000000  0.000000   \n",
              "5   0.000000    0.0000     0.000000  0.000000  0.219569  0.000000  0.000000   \n",
              "6   0.000000    0.0000     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "7   0.000000    0.0000     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "8   0.000000    0.0000     0.000000  0.000000  0.419187  0.000000  0.000000   \n",
              "9   0.000000    0.0000     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "10  0.000000    0.0000     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "11  0.000000    0.0000     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "12  0.000000    0.0000     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "13  0.000000    0.0000     0.000000  0.000000  0.109396  0.000000  0.000000   \n",
              "14  0.000000    0.0000     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "15  0.000000    0.0000     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "16  0.000000    0.0000     0.000000  0.000000  0.134883  0.000000  0.000000   \n",
              "17  0.000000    0.0000     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "18  0.000000    0.0000     0.000000  0.000000  0.227965  0.000000  0.000000   \n",
              "19  0.000000    0.0000     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "20  0.000000    0.0000     0.000000  0.000000  0.293347  0.346861  0.000000   \n",
              "21  0.237845    0.0000     0.237845  0.000000  0.100575  0.000000  0.000000   \n",
              "22  0.000000    0.0000     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "23  0.000000    0.0000     0.000000  0.000000  0.114125  0.000000  0.000000   \n",
              "24  0.000000    0.0000     0.000000  0.000000  0.102456  0.000000  0.000000   \n",
              "25  0.000000    0.0000     0.000000  0.000000  0.206884  0.000000  0.000000   \n",
              "26  0.000000    0.0000     0.000000  0.000000  0.000000  0.000000  0.340215   \n",
              "27  0.000000    0.0000     0.000000  0.000000  0.126297  0.000000  0.000000   \n",
              "28  0.000000    0.0000     0.000000  0.000000  0.138310  0.000000  0.000000   \n",
              "\n",
              "     alphago     also       am  ...      when     where     while       why  \\\n",
              "0   0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "1   0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "2   0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "3   0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "4   0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "5   0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "6   0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "7   0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "8   0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "9   0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "10  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "11  0.000000  0.00000  0.00000  ...  0.000000  0.185738  0.000000  0.000000   \n",
              "12  0.000000  0.29324  0.29324  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "13  0.000000  0.00000  0.00000  ...  0.258705  0.000000  0.000000  0.000000   \n",
              "14  0.307936  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "15  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "16  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "17  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "18  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "19  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "20  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "21  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.237845  0.000000   \n",
              "22  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  1.000000   \n",
              "23  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "24  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "25  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "26  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "27  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "28  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.291317   \n",
              "\n",
              "        will      with   working     would   years       you  \n",
              "0   0.000000  0.000000  0.000000  0.000000  0.2642  0.000000  \n",
              "1   0.000000  0.187753  0.000000  0.000000  0.0000  0.000000  \n",
              "2   0.000000  0.178827  0.000000  0.000000  0.0000  0.000000  \n",
              "3   0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "4   0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "5   0.000000  0.000000  0.259624  0.000000  0.0000  0.000000  \n",
              "6   0.264670  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "7   0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "8   0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "9   0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "10  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "11  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "12  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "13  0.000000  0.210345  0.000000  0.000000  0.0000  0.230416  \n",
              "14  0.000000  0.000000  0.000000  0.000000  0.0000  0.274264  \n",
              "15  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "16  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "17  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "18  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "19  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "20  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "21  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "22  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "23  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "24  0.215799  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "25  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "26  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "27  0.000000  0.000000  0.000000  0.298673  0.0000  0.000000  \n",
              "28  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "\n",
              "[29 rows x 216 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-711430c8-b68d-45d7-b4bf-1983ab361441\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>about</th>\n",
              "      <th>advanced</th>\n",
              "      <th>advancement</th>\n",
              "      <th>after</th>\n",
              "      <th>ai</th>\n",
              "      <th>all</th>\n",
              "      <th>almost</th>\n",
              "      <th>alphago</th>\n",
              "      <th>also</th>\n",
              "      <th>am</th>\n",
              "      <th>...</th>\n",
              "      <th>when</th>\n",
              "      <th>where</th>\n",
              "      <th>while</th>\n",
              "      <th>why</th>\n",
              "      <th>will</th>\n",
              "      <th>with</th>\n",
              "      <th>working</th>\n",
              "      <th>would</th>\n",
              "      <th>years</th>\n",
              "      <th>you</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.2642</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.111720</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.2642</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.230918</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.187753</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.093004</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.178827</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.120739</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.113623</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.219569</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.259624</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.264670</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.419187</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.185738</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.29324</td>\n",
              "      <td>0.29324</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.109396</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.258705</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.210345</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.230416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.307936</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.274264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.134883</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.227965</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.293347</td>\n",
              "      <td>0.346861</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.237845</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.237845</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100575</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.237845</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.114125</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.102456</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.215799</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.206884</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.340215</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.126297</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.298673</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.138310</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.291317</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29 rows × 216 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-711430c8-b68d-45d7-b4bf-1983ab361441')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-711430c8-b68d-45d7-b4bf-1983ab361441 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-711430c8-b68d-45d7-b4bf-1983ab361441');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ede2ebb9-275f-4c08-971b-ef5513fd7f5e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ede2ebb9-275f-4c08-971b-ef5513fd7f5e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ede2ebb9-275f-4c08-971b-ef5513fd7f5e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e57950fc-3f7c-4f21-8018-2f009f65d4b3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('x')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e57950fc-3f7c-4f21-8018-2f009f65d4b3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('x');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "x"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddfXnW_uPREr",
        "outputId": "12f905e9-ea66-4746-eba7-805b1db95d95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(29, 216)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.get_feature_names_out()"
      ],
      "metadata": {
        "id": "fbyk3po0N6HG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c85d26b-fe1f-4385-fd7a-201bf97f1006"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['about', 'advanced', 'advancement', 'after', 'ai', 'all', 'almost',\n",
              "       'alphago', 'also', 'am', 'an', 'and', 'are', 'article', 'as',\n",
              "       'aspects', 'back', 'be', 'because', 'believe', 'billions', 'binds',\n",
              "       'blinkai', 'brain', 'build', 'by', 'can', 'changing', 'chip',\n",
              "       'chips', 'choices', 'cloud', 'club', 'combination', 'combo',\n",
              "       'companies', 'compete', 'components', 'computation', 'concern',\n",
              "       'constraints', 'consumption', 'cool', 'could', 'create', 'crucial',\n",
              "       'currently', 'data', 'days', 'defeated', 'design', 'designed',\n",
              "       'details', 'developed', 'devices', 'don', 'double', 'edge',\n",
              "       'edged', 'efficacy', 'efficiently', 'engine', 'engineering',\n",
              "       'entrance', 'ethical', 'even', 'exactly', 'existing', 'expedited',\n",
              "       'expert', 'fast', 'floor', 'foghorn', 'for', 'framework', 'from',\n",
              "       'further', 'game', 'get', 'giant', 'go', 'google', 'graph', 'hand',\n",
              "       'harder', 'hardware', 'has', 'have', 'helps', 'how', 'however',\n",
              "       'huge', 'human', 'if', 'in', 'including', 'industry', 'inference',\n",
              "       'into', 'invention', 'is', 'isn', 'it', 'its', 'kick', 'kudos',\n",
              "       'large', 'latest', 'learning', 'lose', 'lost', 'low', 'machine',\n",
              "       'make', 'manufacturing', 'many', 'market', 'may', 'methodology',\n",
              "       'milestone', 'millions', 'model', 'models', 'more', 'must',\n",
              "       'named', 'nature', 'nevertheless', 'new', 'next', 'nightmare',\n",
              "       'no', 'not', 'number', 'of', 'on', 'opportunity', 'or', 'other',\n",
              "       'outcome', 'own', 'parameters', 'perform', 'performance',\n",
              "       'performing', 'physical', 'place', 'placement', 'planning',\n",
              "       'player', 'power', 'powerful', 'privacy', 'processing',\n",
              "       'professional', 'project', 'published', 'real', 'referred',\n",
              "       'remember', 'requirements', 'revolution', 'running', 'same',\n",
              "       'satisfied', 'see', 'sent', 'series', 'significantly',\n",
              "       'smartphones', 'software', 'started', 'statement', 'step', 'story',\n",
              "       'such', 'sword', 'team', 'tech', 'technology', 'tensor',\n",
              "       'tensorflow', 'that', 'the', 'their', 'them', 'there', 'they',\n",
              "       'this', 'tightly', 'titles', 'to', 'tpu', 'training', 'try',\n",
              "       'unit', 'us', 'used', 'users', 'using', 'various', 'want', 'was',\n",
              "       'we', 'welcome', 'well', 'when', 'where', 'while', 'why', 'will',\n",
              "       'with', 'working', 'would', 'years', 'you'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tf.get_feature_names_out())"
      ],
      "metadata": {
        "id": "gjBgrFlTNiYA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "919b62b2-3479-466c-c62f-03a458acfe08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "216"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    }
  ]
}